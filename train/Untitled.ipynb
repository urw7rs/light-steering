{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bca7a0-e400-4b82-bb7f-fe2bb089c4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "root = \"/work/dataset\"\n",
    "path_col = \"path\"\n",
    "label_cols = [\"vel\", \"ang\"]\n",
    "\n",
    "pairs = []\n",
    "for clip_path in os.listdir(root):\n",
    "    if not os.path.isdir(os.path.join(root, clip_path)):\n",
    "        continue\n",
    "    elif clip_path[0] == \".\":\n",
    "        continue\n",
    "        \n",
    "    df = pd.read_csv(\n",
    "        os.path.join(root, clip_path, \"label.csv\"),\n",
    "        usecols=[path_col, *label_cols],\n",
    "    )\n",
    "\n",
    "    df[path_col] = df[path_col].apply(lambda p: os.path.join(clip_path, p))\n",
    "\n",
    "    pairs.append(df)\n",
    "\n",
    "\n",
    "df = pd.concat(pairs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa08c47-6f17-4dd2-93ea-e7347d194727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df):\n",
    "    return df[df.loc[:, \"vel\"] > 0]\n",
    "    \n",
    "filtered_df = filter_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ab0a6c-d9da-4f17-a4e4-65a9392da380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_dev_test_split(df):\n",
    "    train_set, test_set = train_test_split(df, test_size=0.02)\n",
    "    test_set, dev_set = train_test_split(test_set, test_size=0.5)\n",
    "    \n",
    "    return train_set, dev_set, test_set\n",
    "\n",
    "def map_splits(df):\n",
    "    splits = train_dev_test_split(df)\n",
    "    \n",
    "    for i, split in enumerate(splits):\n",
    "        split.insert(len(split.columns), \"split\", [i] * len(split))\n",
    "\n",
    "    splits = pd.concat(splits, axis=0)\n",
    "    \n",
    "    return split\n",
    "\n",
    "train, dev, test = train_dev_test_split(filtered_df)\n",
    "split = map_splits(df)\n",
    "print(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99df9d79-b06c-4b87-b50b-fc0e16f60c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "root = \"/work/dataset\"\n",
    "path_col = \"path\"\n",
    "label_cols = [\"vel\", \"ang\"]\n",
    "\n",
    "pairs = []\n",
    "for clip_path in os.listdir(root):\n",
    "    if not os.path.isdir(os.path.join(root, clip_path)):\n",
    "        continue\n",
    "    elif clip_path[0] == \".\":\n",
    "        continue\n",
    "        \n",
    "    df = pd.read_csv(\n",
    "        os.path.join(root, clip_path, \"label.csv\"),\n",
    "        usecols=[path_col, *label_cols],\n",
    "    )\n",
    "\n",
    "    df[path_col] = df[path_col].apply(lambda p: os.path.join(clip_path, p))\n",
    "\n",
    "    pairs.append(df)\n",
    "\n",
    "\n",
    "df = pd.concat(pairs, axis=0)\n",
    "\n",
    "df = filter_df(df)\n",
    "\n",
    "splits = map_splits(df)\n",
    "\n",
    "splits.to_csv(os.path.join(root, \"label.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2505c16-af32-49de-8106-3bdc4892d9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torchvision.io import read_image\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as tsfms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "batch = 64\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "root = \"/work/dataset\"\n",
    "img_size = (64, 48)\n",
    "\n",
    "class CustomDataset(Dataset):  \n",
    "    def __init__(self, root, split, transform=None, target_transform=None):\n",
    "        self.path_col = \"path\"\n",
    "        self.label_cols = [\"vel\", \"ang\"]\n",
    "        \n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "        if split == \"train\":\n",
    "            split = 0\n",
    "        elif split == \"dev\":\n",
    "            split = 1\n",
    "        elif split == \"test\":\n",
    "            split = 2\n",
    "        \n",
    "        df = pd.read_csv(os.path.join(root, \"label.csv\"))\n",
    "        \n",
    "        df.where(df.loc[:, \"split\"] == split)\n",
    "        df.dropna()\n",
    "        \n",
    "        self.df = df.drop([\"split\"], axis=1)\n",
    "\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(os.path.join(self.root, self.df.loc[idx, self.path_col]))\n",
    "\n",
    "        vel_ang = self.df.loc[idx, self.label_cols].values.astype(np.float32)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform is not None:\n",
    "            vel_ang = self.target_transform(vel_ang)\n",
    "\n",
    "        return image, vel_ang\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "resize = tsfms.Compose([\n",
    "    tsfms.ToTensor(),\n",
    "    tsfms.Resize(img_size),\n",
    "])\n",
    "\n",
    "\n",
    "train_set = CustomDataset(root, transform=resize, split=\"train\")\n",
    "dataloader = DataLoader(train_set, batch_size=batch, num_workers=6)\n",
    "\n",
    "mean = 0\n",
    "mean_squared = 0\n",
    "n = 0\n",
    "for x, _ in dataloader:\n",
    "    x = x.to(device)\n",
    "    n += x.shape[1]\n",
    "    with torch.no_grad():\n",
    "        mean += x.mean(dim=(0, 2, 3))\n",
    "        mean_squared += (x ** 2).mean(dim=(0, 2, 3))\n",
    "\n",
    "with torch.no_grad():\n",
    "    mean = mean / n\n",
    "    mean_squared = mean_squared / n\n",
    "    std = torch.sqrt(mean_squared - mean ** 2)\n",
    "\n",
    "mean = mean.cpu()\n",
    "std = std.cpu()\n",
    "\n",
    "print(f\"mean: {mean}, std: {std}\")\n",
    "\n",
    "tsfm_list = [\n",
    "    tsfms.ToTensor(),\n",
    "    tsfms.Resize(img_size),\n",
    "    tsfms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=1),\n",
    "    tsfms.Normalize(mean=mean, std=std),\n",
    "]\n",
    "\n",
    "train_tsfm = tsfms.Compose(tsfm_list)\n",
    "\n",
    "# remove color jitter\n",
    "tsfm_list.pop(2)\n",
    "\n",
    "test_tsfm = tsfms.Compose(tsfm_list)\n",
    "\n",
    "train_set = CustomDataset(root, transform=train_tsfm, split=\"train\")\n",
    "dev_set = CustomDataset(root, transform=test_tsfm, split=\"dev\")\n",
    "test_set = CustomDataset(root, transform=test_tsfm, split=\"test\")\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size=batch, num_workers=6, shuffle=True, pin_memory=True)\n",
    "dev_dataloader = DataLoader(dev_set, batch_size=batch, num_workers=6, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_set, batch_size=batch, num_workers=6, pin_memory=True)\n",
    "\n",
    "modelx = nn.Sequential(\n",
    "    nn.Conv2d(3, 16, 4, 2),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Conv2d(16, 32, 3, 2),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Conv2d(32, 64, 2, 2),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.LazyLinear(100),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.LazyLinear(2)\n",
    ")\n",
    "\n",
    "modelx = modelx.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "epoch = 100\n",
    "\n",
    "for e in range(epoch):    \n",
    "    train_loss = 0\n",
    "    i = 0\n",
    "    for x, y in train_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast():\n",
    "            y_pred = model(x)\n",
    "            y_pred[:, 0] = 1.2 * nn.Sigmoid()(y_pred[:, 0])\n",
    "            y_pred[:, 1] = 0.7 * nn.Tanh()(y_pred[:, 1])\n",
    "        \n",
    "            loss = criterion(y_pred, y)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "\n",
    "        scaler.update()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            train_loss += loss\n",
    "            i += 1\n",
    "        \n",
    "            if i % 100:\n",
    "                print(f\"epoch: {e}, running_loss: {train_loss / i}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "    print(f\"epoch: {e} train loss: {train_loss / i}\")\n",
    "        \n",
    "loss = 0\n",
    "i = 0\n",
    "for x, y in dev_dataloader:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "        \n",
    "    with autocast():\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(x)\n",
    "            y_pred[:, 0] = 1.2 * nn.Sigmoid()(y_pred[:, 0])\n",
    "            y_pred[:, 1] = 0.7 * nn.Tanh()(y_pred[:, 1])\n",
    "\n",
    "            loss += criterion(y_pred, y).item()\n",
    "            i += 1\n",
    "            \n",
    "print(f\"dev loss: {loss / i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be4cf11-366a-4b7d-946e-ce27fffe14f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
